

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Using barrista &mdash; barrista  documentation</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  

  
    <link rel="top" title="barrista  documentation" href="index.html"/>
        <link rel="next" title="API documentation" href="barrista.html"/>
        <link rel="prev" title="Setup" href="setup.html"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> barrista
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="setup.html">Setup</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="">Using <cite>barrista</cite></a><ul>
<li class="toctree-l2"><a class="reference internal" href="#importing-and-configuring-barrista">Importing and configuring barrista</a></li>
<li class="toctree-l2"><a class="reference internal" href="#creating-a-network-specification">Creating a network specification</a></li>
<li class="toctree-l2"><a class="reference internal" href="#visualizing-a-network">Visualizing a network</a></li>
<li class="toctree-l2"><a class="reference internal" href="#importing-a-network-specification">Importing a network specification</a></li>
<li class="toctree-l2"><a class="reference internal" href="#using-a-network">Using a network</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#loading-parameters">Loading parameters</a></li>
<li class="toctree-l3"><a class="reference internal" href="#training-a-network">Training a network</a></li>
<li class="toctree-l3"><a class="reference internal" href="#getting-predictions">Getting predictions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#using-different-architectures-to-fit-and-predict">Using different architectures to <code class="docutils literal"><span class="pre">fit</span></code> and <code class="docutils literal"><span class="pre">predict</span></code></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="barrista.html">API documentation</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="index.html">barrista</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          





<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="index.html">Docs</a> &raquo;</li>
      
    <li>Using <cite>barrista</cite></li>
      <li class="wy-breadcrumbs-aside">
        
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="using-barrista">
<h1>Using <cite>barrista</cite><a class="headerlink" href="#using-barrista" title="Permalink to this headline">¶</a></h1>
<p>This file gives a quite comprehensive walkthrough through nearly all
features offered by barrista. If you want to get your hands dirty right away,
there is a comprehensive example of a VGG-like net being trained and applied
in the file <code class="docutils literal"><span class="pre">example.py</span></code> in the root folder of the barrista package.</p>
<div class="section" id="importing-and-configuring-barrista">
<h2>Importing and configuring barrista<a class="headerlink" href="#importing-and-configuring-barrista" title="Permalink to this headline">¶</a></h2>
<p>If you have <cite>caffe</cite> on your path, you can use barrista right away and
include and use any of its submodules. Otherwise, you can configure it
to use a specific <cite>caffe</cite> version on the fly as follows:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">barrista.config</span>
<span class="c"># This must be done before importing any other submodule.</span>
<span class="n">barrista</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">CAFFE_PYTHON_FOLDER</span> <span class="o">=</span> <span class="s">&#39;your/path&#39;</span>
<span class="n">barrista</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">CAFFE_BIN_FOLDER</span> <span class="o">=</span> <span class="s">&#39;your/bin/path&#39;</span>
<span class="kn">import</span> <span class="nn">barrista.design</span>
<span class="o">...</span>
</pre></div>
</div>
<p>For an exact description of the two parameters, see
<code class="xref py py-data docutils literal"><span class="pre">barrista.config.CAFFE_PYTHON_FOLDER</span></code> and
<code class="xref py py-data docutils literal"><span class="pre">barrista.config.CAFFE_BIN_FOLDER</span></code>.</p>
</div>
<div class="section" id="creating-a-network-specification">
<h2>Creating a network specification<a class="headerlink" href="#creating-a-network-specification" title="Permalink to this headline">¶</a></h2>
<p>The module <a class="reference internal" href="barrista.html#module-barrista.design" title="barrista.design"><code class="xref py py-mod docutils literal"><span class="pre">barrista.design</span></code></a> contains methods and classes to
design <cite>caffe</cite> models. We will use it in the following example to create
a simple, <cite>VGG</cite>-like model:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">barrista.design</span> <span class="kn">as</span> <span class="nn">design</span>
<span class="kn">from</span> <span class="nn">barrista.design</span> <span class="kn">import</span> <span class="p">(</span><span class="n">ConvolutionLayer</span><span class="p">,</span> <span class="n">ReLULayer</span><span class="p">,</span> <span class="n">PoolingLayer</span><span class="p">,</span>
                              <span class="n">DropoutLayer</span><span class="p">,</span> <span class="n">InnerProductLayer</span><span class="p">,</span>
                              <span class="n">SoftmaxLayer</span><span class="p">,</span> <span class="n">SoftmaxWithLossLayer</span><span class="p">,</span>
                              <span class="n">AccuracyLayer</span><span class="p">)</span>

<span class="c"># The only required parameter is a list of lists with the input shape</span>
<span class="c"># specification for the network. In this case, we also specify names</span>
<span class="c"># for the inputs layers.</span>
<span class="n">netspec</span> <span class="o">=</span> <span class="n">design</span><span class="o">.</span><span class="n">NetSpecification</span><span class="p">([[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">51</span><span class="p">,</span> <span class="mi">51</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">]],</span>
                                  <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s">&#39;data&#39;</span><span class="p">,</span> <span class="s">&#39;annotations&#39;</span><span class="p">])</span>

<span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">conv_params</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;Convolution_kernel_size&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
               <span class="s">&#39;Convolution_num_output&#39;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
               <span class="s">&#39;Convolution_pad&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span>

<span class="c"># If not specified, the first top blob for each layer is automatically</span>
<span class="c"># wired with the first bottom of the preceeding layer. If your are using</span>
<span class="c"># multi-in/out layers, you have to manually specify tops and bottoms.</span>

<span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ConvolutionLayer</span><span class="p">(</span><span class="o">**</span><span class="n">conv_params</span><span class="p">))</span>
<span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ReLULayer</span><span class="p">())</span>
<span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ConvolutionLayer</span><span class="p">(</span><span class="o">**</span><span class="n">conv_params</span><span class="p">))</span>
<span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ReLULayer</span><span class="p">())</span>
<span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">PoolingLayer</span><span class="p">(</span><span class="n">Pooling_kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">DropoutLayer</span><span class="p">(</span><span class="n">Dropout_dropout_ratio</span><span class="o">=</span><span class="mf">0.25</span><span class="p">))</span>

<span class="n">conv_params</span><span class="p">[</span><span class="s">&#39;Convolution_num_output&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ConvolutionLayer</span><span class="p">(</span><span class="o">**</span><span class="n">conv_params</span><span class="p">))</span>
<span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ReLULayer</span><span class="p">())</span>
<span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ConvolutionLayer</span><span class="p">(</span><span class="o">**</span><span class="n">conv_params</span><span class="p">))</span>
<span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ReLULayer</span><span class="p">())</span>
<span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">PoolingLayer</span><span class="p">(</span><span class="n">Pooling_kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">DropoutLayer</span><span class="p">(</span><span class="n">Dropout_dropout_ratio</span><span class="o">=</span><span class="mf">0.25</span><span class="p">))</span>

<span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">InnerProductLayer</span><span class="p">(</span><span class="n">InnerProduct_num_output</span><span class="o">=</span><span class="mi">256</span><span class="p">))</span>
<span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ReLULayer</span><span class="p">())</span>
<span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">DropoutLayer</span><span class="p">(</span><span class="n">Dropout_dropout_ratio</span><span class="o">=</span><span class="mf">0.25</span><span class="p">))</span>

<span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">InnerProductLayer</span><span class="p">(</span><span class="n">InnerProduct_num_output</span><span class="o">=</span><span class="mi">10</span><span class="p">))</span>
<span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">SoftmaxLayer</span><span class="p">())</span>

<span class="n">netspec</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span>
</pre></div>
</div>
<p>The layer names are exactly the same as in the prototxt format. All direct
parameters for a layer can be set by using it&#8217;s constructor or later be set
as it&#8217;s object property. If you have to use sub-objects (or rather messages,
in prototxt-speak), they are all available from the object
<a class="reference internal" href="barrista.html#barrista.design.PROTODETAIL" title="barrista.design.PROTODETAIL"><code class="xref py py-data docutils literal"><span class="pre">barrista.design.PROTODETAIL</span></code></a>.</p>
<p>You can now inspect the specification and programatically change its parameters.
To get the prototxt representation, use the method
<a class="reference internal" href="barrista.html#barrista.design.NetSpecification.to_prototxt" title="barrista.design.NetSpecification.to_prototxt"><code class="xref py py-func docutils literal"><span class="pre">barrista.design.NetSpecification.to_prototxt()</span></code></a>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">print</span><span class="p">(</span><span class="n">netspec</span><span class="o">.</span><span class="n">to_prototxt</span><span class="p">())</span>
</pre></div>
</div>
<p>The method has an additional parameter <code class="docutils literal"><span class="pre">output_filename</span></code> that can be used to
directly create prototxt files:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">netspec</span><span class="o">.</span><span class="n">to_prototxt</span><span class="p">(</span><span class="n">output_filename</span><span class="o">=</span><span class="s">&#39;test.prototxt&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="visualizing-a-network">
<h2>Visualizing a network<a class="headerlink" href="#visualizing-a-network" title="Permalink to this headline">¶</a></h2>
<p>It is possible to visualize a network specification or an instantiated
network by calling its <a class="reference internal" href="barrista.html#barrista.design.NetSpecification.visualize" title="barrista.design.NetSpecification.visualize"><code class="xref py py-func docutils literal"><span class="pre">barrista.design.NetSpecification.visualize()</span></code></a>
or <a class="reference internal" href="barrista.html#barrista.net.Net.visualize" title="barrista.net.Net.visualize"><code class="xref py py-func docutils literal"><span class="pre">barrista.net.Net.visualize()</span></code></a> function. It is possible to directly
display it or write it to a file:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="c"># Create the visualization and display it.</span>
<span class="n">viz</span> <span class="o">=</span> <span class="n">netspec</span><span class="o">.</span><span class="n">visualize</span><span class="p">(</span><span class="n">display</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c"># Write it to a file.</span>
<span class="kn">import</span> <span class="nn">cv2</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">imwrite</span><span class="p">(</span><span class="s">&#39;/tmp/test.png&#39;</span><span class="p">,</span> <span class="n">viz</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="importing-a-network-specification">
<h2>Importing a network specification<a class="headerlink" href="#importing-a-network-specification" title="Permalink to this headline">¶</a></h2>
<p>You can work with all your already prepared prototxt files as well! Use the
method <a class="reference internal" href="barrista.html#barrista.design.NetSpecification.from_prototxt" title="barrista.design.NetSpecification.from_prototxt"><code class="xref py py-func docutils literal"><span class="pre">barrista.design.NetSpecification.from_prototxt()</span></code></a> to load
any valid caffe model (of any version!) and inspect and modify it in this
framework:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">netspec_reloaded</span> <span class="o">=</span> <span class="n">design</span><span class="o">.</span><span class="n">NetSpecification</span><span class="o">.</span><span class="n">from_prototxt</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="s">&#39;test.prototxt&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="using-a-network">
<h2>Using a network<a class="headerlink" href="#using-a-network" title="Permalink to this headline">¶</a></h2>
<p>However, apart from diagnostic or logging
purposes, it is not necessary to work with prototxt specifications any more.
Simply run:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">net</span> <span class="o">=</span> <span class="n">netspec</span><span class="o">.</span><span class="n">instantiate</span><span class="p">()</span>
</pre></div>
</div>
<p>to get a fully working network object. It is subclassed from the
<code class="docutils literal"><span class="pre">caffe.Net</span></code>, so it comes with all the methods you are familiar with. But
be prepared for some more convenience! You can set cpu or gpu mode by
using <a class="reference internal" href="barrista.html#barrista.net.set_mode_cpu" title="barrista.net.set_mode_cpu"><code class="xref py py-func docutils literal"><span class="pre">barrista.net.set_mode_cpu()</span></code></a> and
<a class="reference internal" href="barrista.html#barrista.net.set_mode_gpu" title="barrista.net.set_mode_gpu"><code class="xref py py-func docutils literal"><span class="pre">barrista.net.set_mode_gpu()</span></code></a>.</p>
<div class="section" id="loading-parameters">
<h3>Loading parameters<a class="headerlink" href="#loading-parameters" title="Permalink to this headline">¶</a></h3>
<p>With this, the blobs can be loaded as:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">net</span><span class="o">.</span><span class="n">load_blobs_from</span><span class="p">(</span><span class="s">&#39;your/path/to/blobs.caffemodel&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>CAUTION</strong>: The blobs are stored in the <a href="#id1"><span class="problematic" id="id2">``</span></a>.caffemodel``s by name. Blobs will be
matched to network layers with the same name. If a name does not match, the
blob is simply ignored! This gives a powerful mechanic for partially loading
blobs, but be careful when remaining your layers!</p>
</div>
<div class="section" id="training-a-network">
<h3>Training a network<a class="headerlink" href="#training-a-network" title="Permalink to this headline">¶</a></h3>
<p>To train a network, you can use the <cite>scikit-learn</cite> like method
<a class="reference internal" href="barrista.html#barrista.net.Net.fit" title="barrista.net.Net.fit"><code class="xref py py-func docutils literal"><span class="pre">barrista.net.Net.fit()</span></code></a>. It is very powerful and can be used in many
different ways! While maintaining nearly all configurability of the caffe
solvers, it adds callback functionality and is a lot easier to use.</p>
<p>The only required method parameter is the number of iterations that you want
to train your network with. If you configured it with data-layers that are
loading data from external sources, you just have to decide about the kind
of solver to use and probably specify its learning rate. For this example,
we use in-memory data from Python for the training, and some monitors to
generate outputs:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">barrista</span> <span class="kn">import</span> <span class="n">solver</span>
<span class="kn">from</span> <span class="nn">barrista.monitoring</span> <span class="kn">import</span> <span class="n">ProgressIndicator</span><span class="p">,</span> <span class="n">Checkpointer</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">11</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">51</span><span class="p">,</span> <span class="mi">51</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s">&#39;float32&#39;</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">11</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s">&#39;float32&#39;</span><span class="p">)</span>

<span class="c"># Configure our monitors.</span>
<span class="n">progress</span> <span class="o">=</span> <span class="n">ProgressIndicator</span><span class="p">()</span>
<span class="n">checkptr</span> <span class="o">=</span> <span class="n">Checkpointer</span><span class="p">(</span><span class="s">&#39;test_net_&#39;</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
<span class="c"># Run the training.</span>
<span class="n">net</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">solver</span><span class="o">.</span><span class="n">SGDSolver</span><span class="p">(</span><span class="n">base_lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">),</span>
        <span class="p">{</span><span class="s">&#39;data&#39;</span><span class="p">:</span> <span class="n">X</span><span class="p">,</span>  <span class="c"># &#39;data&#39; and &#39;annotations&#39; are the input layer names.</span>
         <span class="s">&#39;annotations&#39;</span><span class="p">:</span> <span class="n">Y</span><span class="p">},</span> <span class="c"># optional (if you have, e.g., a DataLayer)</span>
        <span class="n">test_interval</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>  <span class="c"># optional</span>
        <span class="n">X_val</span><span class="o">=</span><span class="p">{</span><span class="s">&#39;data&#39;</span><span class="p">:</span> <span class="n">X</span><span class="p">,</span>  <span class="c"># optional</span>
               <span class="s">&#39;annotations&#39;</span><span class="p">:</span> <span class="n">Y</span><span class="p">},</span>
        <span class="n">after_batch_callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">progress</span><span class="p">,</span> <span class="n">checkptr</span><span class="p">],</span>  <span class="c"># optional</span>
        <span class="n">after_test_callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">progress</span><span class="p">])</span>  <span class="c"># optional</span>
</pre></div>
</div>
<p>The parameters <code class="docutils literal"><span class="pre">test_interval</span></code>, <code class="docutils literal"><span class="pre">X_val</span></code> and <code class="docutils literal"><span class="pre">Y_val</span></code> are optional. If they
are specified, there is a test performed on the validation set in
regular intervals.</p>
<p>Note that all iteration parameters are speaking of &#8216;true&#8217; iterations, i.e.,
not batch iterations but sample iterations. This is, why they must be a
multiple of the batch size (e.g., for a network with a batch size of 10,
you have to do at least 10 training iterations, and one batch will be
used for the training).</p>
<p>The <a class="reference internal" href="barrista.html#barrista.monitoring.Checkpointer" title="barrista.monitoring.Checkpointer"><code class="xref py py-class docutils literal"><span class="pre">barrista.monitoring.Checkpointer</span></code></a> is used to write the network
blobs to a file, which can be loaded later using the function
<a class="reference internal" href="barrista.html#barrista.net.Net.load_blobs_from" title="barrista.net.Net.load_blobs_from"><code class="xref py py-func docutils literal"><span class="pre">barrista.net.Net.load_blobs_from()</span></code></a>. There is, however,
currently no monitor implemented to store the solverstate.</p>
</div>
<div class="section" id="getting-predictions">
<h3>Getting predictions<a class="headerlink" href="#getting-predictions" title="Permalink to this headline">¶</a></h3>
<p>In the spirit of the <cite>scikit-learn</cite> library, we added the method
<a class="reference internal" href="barrista.html#barrista.net.Net.predict" title="barrista.net.Net.predict"><code class="xref py py-func docutils literal"><span class="pre">barrista.net.Net.predict()</span></code></a> to get predictions for you, while
maintaining a clear separation of data preprocessing:</p>
<ul class="simple">
<li>It is YOUR responsibility to prepare the data in an iterable object
of numpy arrays with the correctly matching first dimension (i.e.,
the number of channels).</li>
<li>The method will match the data to the input size of the network and
forward propagate it in batches.</li>
</ul>
<p>By default, it rescales the examples using
bicubic interpolation to the full input field size of the network, but if you
set <code class="docutils literal"><span class="pre">pad_instead_of_rescale</span></code>, they will be instead padded to be centered in
the input field. If you choose padding and <code class="docutils literal"><span class="pre">return_unprocessed_outputs</span></code> is
set to <code class="docutils literal"><span class="pre">False</span></code>, the data will automatically be reduced to the relevant
area.</p>
<p>You may
optionally set callback functions in between the batches to, e.g.,
update progress indicators:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">barrista.monitoring</span> <span class="kn">import</span> <span class="n">ProgressIndicator</span>
<span class="c"># Only the number of channels (3) must match.</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">20</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span>
                      <span class="n">after_batch_callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">ProgressIndicator</span><span class="p">()])</span>
<span class="c"># This works for single-input networks. If you have multiple inputs, just</span>
<span class="c"># provide a dicitonary of layer-names with arrays, as for the fit-method.</span>
<span class="c"># Similarly, in case of a single-output network, this method returns a</span>
<span class="c"># single list of predictions, or, in case of a multi-output network,</span>
<span class="c"># a dictionary of output layer names with their respective output lists.</span>
<span class="k">print</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="using-different-architectures-to-fit-and-predict">
<h2>Using different architectures to <code class="docutils literal"><span class="pre">fit</span></code> and <code class="docutils literal"><span class="pre">predict</span></code><a class="headerlink" href="#using-different-architectures-to-fit-and-predict" title="Permalink to this headline">¶</a></h2>
<p>You have many possibilities to condition the network layout for the very same
network depending on it&#8217;s state. It has
<code class="xref py py-attr docutils literal"><span class="pre">barrista.design.NetSpecification.phase</span></code>,
<code class="xref py py-attr docutils literal"><span class="pre">barrista.design.NetSpecification.level</span></code> and
<code class="xref py py-attr docutils literal"><span class="pre">barrista.design.NetSpecification.stages</span></code>. The <code class="docutils literal"><span class="pre">phase</span></code> is used
to configure the net during the &#8216;fit&#8217; progress to alternate between training
and validation sets. We offer a simple way of using the <code class="docutils literal"><span class="pre">stages</span></code> to switch
between different architectures for &#8216;fit&#8217; and &#8216;predict&#8217;.</p>
<p>When designing a network, you can specify the optional parameters
<code class="docutils literal"><span class="pre">predict_inputs</span></code> and <code class="docutils literal"><span class="pre">predict_input_shapes</span></code>. If you do so, when
instantiating the net, a second version of the net with the stages set only
to <code class="docutils literal"><span class="pre">predict</span></code> is created (with shared weights with the main network) and
automatically used when calling the <a class="reference internal" href="barrista.html#barrista.net.Net.predict" title="barrista.net.Net.predict"><code class="xref py py-func docutils literal"><span class="pre">barrista.net.Net.predict()</span></code></a>
method (for an illustration of this behavior, see also the documentation for
<a class="reference internal" href="barrista.html#barrista.design.NetSpecification" title="barrista.design.NetSpecification"><code class="xref py py-class docutils literal"><span class="pre">barrista.design.NetSpecification</span></code></a>).
This is a very convenient way of using your networks comfortably and
just as expected, while maintaining a high level of convenience:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">netspec</span> <span class="o">=</span> <span class="n">design</span><span class="o">.</span><span class="n">NetSpecification</span><span class="p">([[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">51</span><span class="p">,</span> <span class="mi">51</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">]],</span>
                                  <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s">&#39;data&#39;</span><span class="p">,</span> <span class="s">&#39;annotations&#39;</span><span class="p">],</span>
                                  <span class="n">predict_inputs</span><span class="o">=</span><span class="p">[</span><span class="s">&#39;data&#39;</span><span class="p">],</span>
                                  <span class="n">predict_input_shapes</span><span class="o">=</span><span class="p">[[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">51</span><span class="p">,</span> <span class="mi">51</span><span class="p">]])</span>
<span class="c"># ... add layers as usual.</span>
<span class="c"># This is the last regular one. Use `tops` to give its outputs a</span>
<span class="c"># simple-to-remember name.</span>
<span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">InnerProductLayer</span><span class="p">(</span><span class="n">tops</span><span class="o">=</span><span class="p">[</span><span class="s">&#39;net_out&#39;</span><span class="p">],</span> <span class="n">InnerProduct_num_output</span><span class="o">=</span><span class="mi">10</span><span class="p">))</span>
<span class="c"># Add a layer for being used by the `predict` method:</span>
<span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">SoftmaxLayer</span><span class="p">(</span><span class="n">bottoms</span><span class="o">=</span><span class="p">[</span><span class="s">&#39;net_out&#39;</span><span class="p">],</span>
                           <span class="n">tops</span><span class="o">=</span><span class="p">[</span><span class="s">&#39;out&#39;</span><span class="p">],</span>
                           <span class="n">include_stages</span><span class="o">=</span><span class="p">[</span><span class="s">&#39;predict&#39;</span><span class="p">]))</span>
<span class="c"># Add layers for being used by the `fit` method:</span>
<span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">SoftmaxWithLossLayer</span><span class="p">(</span><span class="n">bottoms</span><span class="o">=</span><span class="p">[</span><span class="s">&#39;net_out&#39;</span><span class="p">,</span> <span class="s">&#39;annotations&#39;</span><span class="p">],</span>
                                   <span class="n">include_stages</span><span class="o">=</span><span class="p">[</span><span class="s">&#39;fit&#39;</span><span class="p">]))</span>
<span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">AccuracyLayer</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s">&#39;accuracy&#39;</span><span class="p">,</span>
                            <span class="n">bottoms</span><span class="o">=</span><span class="p">[</span><span class="s">&#39;net_out&#39;</span><span class="p">,</span> <span class="s">&#39;annotations&#39;</span><span class="p">],</span>
                            <span class="n">include_stages</span><span class="o">=</span><span class="p">[</span><span class="s">&#39;fit&#39;</span><span class="p">]))</span>
</pre></div>
</div>
<p>Remember that you can additionally use any other conditional criteria such as
<code class="docutils literal"><span class="pre">phase</span></code> and <code class="docutils literal"><span class="pre">level</span></code> to further customize the net.</p>
<p>Once instantiated, this net will output loss and accuracy when it&#8217;s
<a class="reference internal" href="barrista.html#barrista.net.Net.fit" title="barrista.net.Net.fit"><code class="xref py py-func docutils literal"><span class="pre">barrista.net.Net.fit()</span></code></a>
method is called, and output softmaxed values when it&#8217;s
<a class="reference internal" href="barrista.html#barrista.net.Net.predict" title="barrista.net.Net.predict"><code class="xref py py-func docutils literal"><span class="pre">barrista.net.Net.predict()</span></code></a> method is called. You can find an example
for this in the file <code class="docutils literal"><span class="pre">barrista/example.py</span></code>.</p>
</div>
</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="barrista.html" class="btn btn-neutral float-right" title="API documentation" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="setup.html" class="btn btn-neutral" title="Setup" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016, University of Tuebingen.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>